{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "LeNetTensorFlow.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choiwhmarco/COGS_181/blob/main/LeNetTensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtLdFGs8nuze"
      },
      "source": [
        "LeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1bpte4rnuze"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sCaCGhHnuzf"
      },
      "source": [
        "#loda data\n",
        "import glob\n",
        "train_images_dir ='./data/tiny-imagenet-200/train/'\n",
        "test_images_dir ='./data/tiny-imagenet-200/test/'\n",
        "val_images_dir ='./data/tiny-imagenet-200/val/'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pGme_G-nuzf"
      },
      "source": [
        "#train label\n",
        "label_fliepath='./data/tiny-imagenet-200/wnids.txt'\n",
        "file_object = open(label_fliepath,'r')\n",
        "label_dict={}\n",
        "i=0\n",
        "for line in file_object:\n",
        "    l=line.rstrip('\\n')\n",
        "    label_dict[l]=i\n",
        "    i=i+1\n",
        "file_object.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE1A7rkknuzf"
      },
      "source": [
        "#train data\n",
        "traindata=np.zeros([200*500,64,64,3],dtype ='float32')\n",
        "trainlabel=np.zeros([200*500,200],dtype ='float32')\n",
        "for key in label_dict:\n",
        "    path=glob.glob(train_images_dir+key+'/images/*.JPEG')   \n",
        "    i=0\n",
        "    for imageFile in path:\n",
        "        img = cv2.imread(imageFile)  #bgr\n",
        "        traindata[label_dict[key]*500+i]=img\n",
        "        trainlabel[label_dict[key]*500+i][label_dict[key]]=1\n",
        "        i=i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpD0oXZ5nuzf"
      },
      "source": [
        "#test data\n",
        "testdata=np.zeros([10000,64,64,3],dtype ='float32')\n",
        "path=glob.glob(test_images_dir+'images/*.JPEG')\n",
        "i=0\n",
        "for imageFile in path:\n",
        "    img = cv2.imread(imageFile)  #bgr\n",
        "    testdata[i]=img\n",
        "    i=i+1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4QKSoU9nuzg"
      },
      "source": [
        "#val label\n",
        "vallabel=np.zeros([10000,200],dtype ='float32')\n",
        "valpath=[None]*10000\n",
        "path=val_images_dir+'/val_annotations.txt'\n",
        "file_object = open(path,'r')\n",
        "i=0\n",
        "for line in file_object:\n",
        "    l=line.split()\n",
        "    valpath[i]=l[0]\n",
        "    vallabel[i][label_dict[l[1]]]=1\n",
        "    i=i+1\n",
        "file_object.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBQx51w1nuzg"
      },
      "source": [
        "#val data\n",
        "valdata=np.zeros([10000,64,64,3],dtype ='float32')\n",
        "for i in range(10000):\n",
        "    img = cv2.imread(val_images_dir+'images/'+valpath[i])  #bgr\n",
        "    valdata[i]=img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aC0mDLInuzg"
      },
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmBURKEanuzh"
      },
      "source": [
        "#----Weight Initialization---#\n",
        "#One should generally initialize weights with a small amount of noise for symmetry breaking, and to prevent 0 gradients\n",
        "def weight_variable(shape):\n",
        "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
        "    return tf.Variable(initial)\n",
        "def bias_variable(shape):\n",
        "    initial = tf.constant(0.1, shape=shape)\n",
        "    return tf.Variable(initial)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcH1dRxtnuzh"
      },
      "source": [
        "#Convolution and Pooling\n",
        "#Our convolutions uses a stride of one and are zero padded so that the output is the same size as the input.\n",
        "#Our pooling is plain old max pooling over 2x2 blocks\n",
        "def conv2d(x, W):\n",
        "     return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
        "def max_pool_2x2(x):   \n",
        "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNLyzTTNnuzh"
      },
      "source": [
        "#----input and output----#\n",
        "x = tf.placeholder(tf.float32,[ None,64, 64, 3])\n",
        "y = tf.placeholder(tf.float32,[ None,200])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqOlTzBPnuzh"
      },
      "source": [
        "#----first convolution layer----#\n",
        "#64x64x3 ->32x32x32\n",
        "W_conv1 = weight_variable([3, 3, 3, 32])\n",
        "b_conv1 = bias_variable([32])\n",
        "h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)\n",
        "h_pool1 = max_pool_2x2(h_conv1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ubp6SVu3nuzh"
      },
      "source": [
        "#----second convolution layer----#\n",
        "#32x32x32->16x16x64\n",
        "W_conv2 = weight_variable([3,3,32,64])\n",
        "b_conv2 = bias_variable([64])\n",
        "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
        "h_pool2 = max_pool_2x2(h_conv2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "genM0rrEnuzi"
      },
      "source": [
        "#----second convolution layer----#\n",
        "#16x16x64->8x8x64\n",
        "W_conv3 = weight_variable([3,3,64,64])\n",
        "b_conv3 = bias_variable([64])\n",
        "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
        "h_pool3 = max_pool_2x2(h_conv3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKU0d4F3nuzi"
      },
      "source": [
        "#----fully connected layer----#\n",
        "W_fc1 = weight_variable([16 * 16* 64, 1024])\n",
        "b_fc1 = bias_variable([1024])\n",
        "h_pool3_flat = tf.reshape(h_pool3, [-1, 16 * 16* 64])\n",
        "h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ARxaulqnuzi"
      },
      "source": [
        "#----read out layer----#\n",
        "W_fc2 = weight_variable([1024, 200])\n",
        "b_fc2 = bias_variable([200])\n",
        "y_conv = tf.nn.softmax(tf.matmul(h_fc1, W_fc2) + b_fc2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEJ5Ml3jnuzi"
      },
      "source": [
        "cross_entropy = -tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=y_conv)) \n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
        "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aPEn5rsnuzi"
      },
      "source": [
        "def next_batch(size=50):\n",
        "    index=np.random.randint(0,200*500,size)\n",
        "    x1=traindata[index]\n",
        "    y1=trainlabel[index]\n",
        "    return x1,y1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWlq04Apnuzi"
      },
      "source": [
        "if 'session' in locals() and tf.session is not None:\n",
        "    print('Close interactive session')\n",
        "    tensorflow.session.close()\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A32-pxvnuzj"
      },
      "source": [
        "for i in range(1000):\n",
        "    batchx,batchy =next_batch(200)\n",
        "    train_step.run(session = sess, feed_dict = {x:batchx, y:batchy})\n",
        "    if (i+1) % 100 == 0:\n",
        "        train_accuracy = accuracy.eval(session = sess,feed_dict = {x:batchx, y:batchy})\n",
        "        print(\"step %d, train_accuracy %g\" %(i, train_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CMufqEVnuzj"
      },
      "source": [
        "train_accuracy = accuracy.eval(session = sess,feed_dict = {x:traindata.reshape(200*500,64,64,3), y_:trainlabel.reshape(200*500,1)})\n",
        "print(\"test accuracy %g\"%train_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}